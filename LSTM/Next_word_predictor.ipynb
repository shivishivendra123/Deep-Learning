{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Long dataset with varied sentences\n",
    "sentences = [\n",
    "    \"The sun sets in the west, casting a golden hue across the sky as the birds return to their nests.\",\n",
    "    \"Artificial intelligence is transforming the world by enabling machines to learn and make decisions autonomously.\",\n",
    "    \"She enjoys reading science fiction books because they allow her to explore futuristic concepts and new possibilities.\",\n",
    "    \"The cat sat on the windowsill, lazily watching the raindrops race down the glass pane.\",\n",
    "    \"He plays the guitar every evening, filling the house with melodious tunes that bring a sense of peace.\",\n",
    "    \"Machine learning models improve with more data, allowing them to make better predictions and understand patterns.\",\n",
    "    \"They traveled to Paris for their vacation, visiting famous landmarks such as the Eiffel Tower and the Louvre Museum.\",\n",
    "    \"Cooking is both an art and a science, requiring creativity, precision, and an understanding of flavors.\",\n",
    "    \"The rain poured heavily throughout the night, creating a rhythmic sound that lulled everyone to sleep.\",\n",
    "    \"Space exploration is advancing rapidly, with scientists working on missions to Mars and beyond.\",\n",
    "    \"She practiced yoga every morning, believing it helped her maintain both physical health and mental clarity.\",\n",
    "    \"Quantum computing is a fascinating field that has the potential to revolutionize problem-solving in science and technology.\",\n",
    "    \"The artist painted a beautiful landscape, capturing the essence of nature with every brushstroke on the canvas.\",\n",
    "    \"They watched a thrilling movie last night, filled with unexpected twists and a captivating storyline.\",\n",
    "    \"Technology is evolving at an incredible pace, influencing every aspect of human life, from communication to medicine.\",\n",
    "    \"The mountain peaks were covered in snow, glistening under the morning sun as hikers prepared for their journey.\",\n",
    "    \"He solved the puzzle in just five minutes, impressing everyone with his sharp thinking and problem-solving skills.\",\n",
    "    \"They adopted a cute little puppy, instantly falling in love with its playful nature and adorable eyes.\",\n",
    "    \"The ocean waves crashed against the shore, creating a soothing melody that resonated with the tranquility of the beach.\",\n",
    "    \"She learned a new language in a year, practicing daily and immersing herself in books, movies, and conversations.\",\n",
    "    \"The library was filled with books of every genre, offering knowledge and entertainment to avid readers.\",\n",
    "    \"He built a treehouse in his backyard, creating a secret hideaway where he could read and dream.\",\n",
    "    \"She discovered an ancient artifact while exploring the old ruins, sparking curiosity among archaeologists.\",\n",
    "    \"The scientist conducted experiments to understand the effects of climate change on marine ecosystems.\",\n",
    "    \"They hiked through the dense forest, listening to the sounds of birds and rustling leaves.\",\n",
    "    \"The detective carefully examined the crime scene, searching for clues that could solve the mystery.\",\n",
    "    \"He spent hours programming a new application, determined to solve a problem using innovative algorithms.\",\n",
    "    \"She wrote in her journal every night, documenting her thoughts, experiences, and dreams for the future.\",\n",
    "    \"The little boy watched in awe as the magician performed incredible tricks on stage.\",\n",
    "    \"They set up a telescope in the backyard to observe the stars and planets in the night sky.\",\n",
    "    \"The chef prepared a delicious five-course meal, impressing the guests with exquisite flavors and presentation.\",\n",
    "    \"The athlete trained rigorously for the marathon, pushing his limits to achieve his personal best time.\",\n",
    "    \"They planted a vegetable garden, growing fresh tomatoes, cucumbers, and peppers for their kitchen.\",\n",
    "    \"The city was bustling with energy, with people rushing to work, street vendors selling food, and cars honking.\",\n",
    "    \"She spent the afternoon painting a mural, bringing vibrant colors to an otherwise dull wall.\",\n",
    "    \"The pilot skillfully navigated the plane through turbulent weather, ensuring a smooth landing for the passengers.\",\n",
    "    \"The musician composed a new symphony, blending classical and modern elements to create a masterpiece.\",\n",
    "    \"They organized a surprise birthday party, inviting friends and decorating the venue with balloons and lights.\",\n",
    "    \"The historian studied ancient manuscripts, uncovering secrets about lost civilizations.\",\n",
    "    \"The doctor worked tirelessly in the hospital, treating patients and saving lives.\",\n",
    "    \"The astronaut trained for years before embarking on a mission to the International Space Station.\",\n",
    "    \"They designed an innovative gadget that could translate spoken language in real time.\",\n",
    "    \"The novelist spent years writing her book, carefully crafting characters and an engaging plot.\",\n",
    "    \"The storm raged on outside, with thunderclaps and lightning illuminating the dark sky.\",\n",
    "    \"The farmer woke up early to tend to his crops, ensuring they received enough water and care.\",\n",
    "    \"The philosopher pondered deep questions about the meaning of life and human existence.\",\n",
    "    \"The engineer developed a new AI system that could assist doctors in diagnosing diseases.\",\n",
    "    \"The explorer ventured into the Amazon rainforest, discovering rare species of plants and animals.\",\n",
    "    \"The teacher inspired students with engaging lessons that made learning fun and exciting.\",\n",
    "    \"The firefighter bravely rushed into the burning building, rescuing people trapped inside.\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import os\n",
    "story = []\n",
    "for filename in os.listdir('/Users/shivendragupta/Desktop/Deep Learning/LSTM/data'):\n",
    "    f = open(os.path.join('/Users/shivendragupta/Desktop/Deep Learning/LSTM/data',filename), errors=\"ignore\")\n",
    "    corpus = f.read()\n",
    "    raw_sent = sent_tokenize(corpus)\n",
    "    for sent in raw_sent:\n",
    "        story.append(simple_preprocess(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token='<nothing>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<nothing>': 1,\n",
       " 'the': 2,\n",
       " 'and': 3,\n",
       " 'a': 4,\n",
       " 'to': 5,\n",
       " 'in': 6,\n",
       " 'with': 7,\n",
       " 'they': 8,\n",
       " 'of': 9,\n",
       " 'that': 10,\n",
       " 'for': 11,\n",
       " 'on': 12,\n",
       " 'an': 13,\n",
       " 'she': 14,\n",
       " 'every': 15,\n",
       " 'is': 16,\n",
       " 'her': 17,\n",
       " 'new': 18,\n",
       " 'he': 19,\n",
       " 'his': 20,\n",
       " 'as': 21,\n",
       " 'their': 22,\n",
       " 'night': 23,\n",
       " 'could': 24,\n",
       " 'sky': 25,\n",
       " 'science': 26,\n",
       " 'books': 27,\n",
       " 'creating': 28,\n",
       " 'problem': 29,\n",
       " 'spent': 30,\n",
       " 'sun': 31,\n",
       " 'birds': 32,\n",
       " 'make': 33,\n",
       " 'learning': 34,\n",
       " 'understand': 35,\n",
       " 'both': 36,\n",
       " 'flavors': 37,\n",
       " 'everyone': 38,\n",
       " 'space': 39,\n",
       " 'morning': 40,\n",
       " 'solving': 41,\n",
       " 'technology': 42,\n",
       " 'nature': 43,\n",
       " 'watched': 44,\n",
       " 'filled': 45,\n",
       " 'incredible': 46,\n",
       " 'human': 47,\n",
       " 'life': 48,\n",
       " 'prepared': 49,\n",
       " 'five': 50,\n",
       " 'impressing': 51,\n",
       " 'little': 52,\n",
       " 'language': 53,\n",
       " 'was': 54,\n",
       " 'backyard': 55,\n",
       " 'ancient': 56,\n",
       " 'through': 57,\n",
       " 'carefully': 58,\n",
       " 'solve': 59,\n",
       " 'innovative': 60,\n",
       " 'up': 61,\n",
       " 'trained': 62,\n",
       " 'time': 63,\n",
       " 'people': 64,\n",
       " 'ensuring': 65,\n",
       " 'about': 66,\n",
       " 'years': 67,\n",
       " 'engaging': 68,\n",
       " 'into': 69,\n",
       " 'the sun sets in the west, casting a golden hue across the sky as the birds return to their nests.': 70,\n",
       " 'artificial intelligence is transforming the world by enabling machines to learn and make decisions autonomously.': 71,\n",
       " 'she enjoys reading science fiction books because they allow her to explore futuristic concepts and new possibilities.': 72,\n",
       " 'the cat sat on the windowsill, lazily watching the raindrops race down the glass pane.': 73,\n",
       " 'he plays the guitar every evening, filling the house with melodious tunes that bring a sense of peace.': 74,\n",
       " 'machine learning models improve with more data, allowing them to make better predictions and understand patterns.': 75,\n",
       " 'they traveled to paris for their vacation, visiting famous landmarks such as the eiffel tower and the louvre museum.': 76,\n",
       " 'cooking is both an art and a science, requiring creativity, precision, and an understanding of flavors.': 77,\n",
       " 'the rain poured heavily throughout the night, creating a rhythmic sound that lulled everyone to sleep.': 78,\n",
       " 'space exploration is advancing rapidly, with scientists working on missions to mars and beyond.': 79,\n",
       " 'she practiced yoga every morning, believing it helped her maintain both physical health and mental clarity.': 80,\n",
       " 'quantum computing is a fascinating field that has the potential to revolutionize problem-solving in science and technology.': 81,\n",
       " 'the artist painted a beautiful landscape, capturing the essence of nature with every brushstroke on the canvas.': 82,\n",
       " 'they watched a thrilling movie last night, filled with unexpected twists and a captivating storyline.': 83,\n",
       " 'technology is evolving at an incredible pace, influencing every aspect of human life, from communication to medicine.': 84,\n",
       " 'the mountain peaks were covered in snow, glistening under the morning sun as hikers prepared for their journey.': 85,\n",
       " 'he solved the puzzle in just five minutes, impressing everyone with his sharp thinking and problem-solving skills.': 86,\n",
       " 'they adopted a cute little puppy, instantly falling in love with its playful nature and adorable eyes.': 87,\n",
       " 'the ocean waves crashed against the shore, creating a soothing melody that resonated with the tranquility of the beach.': 88,\n",
       " 'she learned a new language in a year, practicing daily and immersing herself in books, movies, and conversations.': 89,\n",
       " 'the library was filled with books of every genre, offering knowledge and entertainment to avid readers.': 90,\n",
       " 'he built a treehouse in his backyard, creating a secret hideaway where he could read and dream.': 91,\n",
       " 'she discovered an ancient artifact while exploring the old ruins, sparking curiosity among archaeologists.': 92,\n",
       " 'the scientist conducted experiments to understand the effects of climate change on marine ecosystems.': 93,\n",
       " 'they hiked through the dense forest, listening to the sounds of birds and rustling leaves.': 94,\n",
       " 'the detective carefully examined the crime scene, searching for clues that could solve the mystery.': 95,\n",
       " 'he spent hours programming a new application, determined to solve a problem using innovative algorithms.': 96,\n",
       " 'she wrote in her journal every night, documenting her thoughts, experiences, and dreams for the future.': 97,\n",
       " 'the little boy watched in awe as the magician performed incredible tricks on stage.': 98,\n",
       " 'they set up a telescope in the backyard to observe the stars and planets in the night sky.': 99,\n",
       " 'the chef prepared a delicious five-course meal, impressing the guests with exquisite flavors and presentation.': 100,\n",
       " 'the athlete trained rigorously for the marathon, pushing his limits to achieve his personal best time.': 101,\n",
       " 'they planted a vegetable garden, growing fresh tomatoes, cucumbers, and peppers for their kitchen.': 102,\n",
       " 'the city was bustling with energy, with people rushing to work, street vendors selling food, and cars honking.': 103,\n",
       " 'she spent the afternoon painting a mural, bringing vibrant colors to an otherwise dull wall.': 104,\n",
       " 'the pilot skillfully navigated the plane through turbulent weather, ensuring a smooth landing for the passengers.': 105,\n",
       " 'the musician composed a new symphony, blending classical and modern elements to create a masterpiece.': 106,\n",
       " 'they organized a surprise birthday party, inviting friends and decorating the venue with balloons and lights.': 107,\n",
       " 'the historian studied ancient manuscripts, uncovering secrets about lost civilizations.': 108,\n",
       " 'the doctor worked tirelessly in the hospital, treating patients and saving lives.': 109,\n",
       " 'the astronaut trained for years before embarking on a mission to the international space station.': 110,\n",
       " 'they designed an innovative gadget that could translate spoken language in real time.': 111,\n",
       " 'the novelist spent years writing her book, carefully crafting characters and an engaging plot.': 112,\n",
       " 'the storm raged on outside, with thunderclaps and lightning illuminating the dark sky.': 113,\n",
       " 'the farmer woke up early to tend to his crops, ensuring they received enough water and care.': 114,\n",
       " 'the philosopher pondered deep questions about the meaning of life and human existence.': 115,\n",
       " 'the engineer developed a new ai system that could assist doctors in diagnosing diseases.': 116,\n",
       " 'the explorer ventured into the amazon rainforest, discovering rare species of plants and animals.': 117,\n",
       " 'the teacher inspired students with engaging lessons that made learning fun and exciting.': 118,\n",
       " 'the firefighter bravely rushed into the burning building, rescuing people trapped inside.': 119,\n",
       " 'sets': 120,\n",
       " 'west': 121,\n",
       " 'casting': 122,\n",
       " 'golden': 123,\n",
       " 'hue': 124,\n",
       " 'across': 125,\n",
       " 'return': 126,\n",
       " 'nests': 127,\n",
       " 'artificial': 128,\n",
       " 'intelligence': 129,\n",
       " 'transforming': 130,\n",
       " 'world': 131,\n",
       " 'by': 132,\n",
       " 'enabling': 133,\n",
       " 'machines': 134,\n",
       " 'learn': 135,\n",
       " 'decisions': 136,\n",
       " 'autonomously': 137,\n",
       " 'enjoys': 138,\n",
       " 'reading': 139,\n",
       " 'fiction': 140,\n",
       " 'because': 141,\n",
       " 'allow': 142,\n",
       " 'explore': 143,\n",
       " 'futuristic': 144,\n",
       " 'concepts': 145,\n",
       " 'possibilities': 146,\n",
       " 'cat': 147,\n",
       " 'sat': 148,\n",
       " 'windowsill': 149,\n",
       " 'lazily': 150,\n",
       " 'watching': 151,\n",
       " 'raindrops': 152,\n",
       " 'race': 153,\n",
       " 'down': 154,\n",
       " 'glass': 155,\n",
       " 'pane': 156,\n",
       " 'plays': 157,\n",
       " 'guitar': 158,\n",
       " 'evening': 159,\n",
       " 'filling': 160,\n",
       " 'house': 161,\n",
       " 'melodious': 162,\n",
       " 'tunes': 163,\n",
       " 'bring': 164,\n",
       " 'sense': 165,\n",
       " 'peace': 166,\n",
       " 'machine': 167,\n",
       " 'models': 168,\n",
       " 'improve': 169,\n",
       " 'more': 170,\n",
       " 'data': 171,\n",
       " 'allowing': 172,\n",
       " 'them': 173,\n",
       " 'better': 174,\n",
       " 'predictions': 175,\n",
       " 'patterns': 176,\n",
       " 'traveled': 177,\n",
       " 'paris': 178,\n",
       " 'vacation': 179,\n",
       " 'visiting': 180,\n",
       " 'famous': 181,\n",
       " 'landmarks': 182,\n",
       " 'such': 183,\n",
       " 'eiffel': 184,\n",
       " 'tower': 185,\n",
       " 'louvre': 186,\n",
       " 'museum': 187,\n",
       " 'cooking': 188,\n",
       " 'art': 189,\n",
       " 'requiring': 190,\n",
       " 'creativity': 191,\n",
       " 'precision': 192,\n",
       " 'understanding': 193,\n",
       " 'rain': 194,\n",
       " 'poured': 195,\n",
       " 'heavily': 196,\n",
       " 'throughout': 197,\n",
       " 'rhythmic': 198,\n",
       " 'sound': 199,\n",
       " 'lulled': 200,\n",
       " 'sleep': 201,\n",
       " 'exploration': 202,\n",
       " 'advancing': 203,\n",
       " 'rapidly': 204,\n",
       " 'scientists': 205,\n",
       " 'working': 206,\n",
       " 'missions': 207,\n",
       " 'mars': 208,\n",
       " 'beyond': 209,\n",
       " 'practiced': 210,\n",
       " 'yoga': 211,\n",
       " 'believing': 212,\n",
       " 'it': 213,\n",
       " 'helped': 214,\n",
       " 'maintain': 215,\n",
       " 'physical': 216,\n",
       " 'health': 217,\n",
       " 'mental': 218,\n",
       " 'clarity': 219,\n",
       " 'quantum': 220,\n",
       " 'computing': 221,\n",
       " 'fascinating': 222,\n",
       " 'field': 223,\n",
       " 'has': 224,\n",
       " 'potential': 225,\n",
       " 'revolutionize': 226,\n",
       " 'artist': 227,\n",
       " 'painted': 228,\n",
       " 'beautiful': 229,\n",
       " 'landscape': 230,\n",
       " 'capturing': 231,\n",
       " 'essence': 232,\n",
       " 'brushstroke': 233,\n",
       " 'canvas': 234,\n",
       " 'thrilling': 235,\n",
       " 'movie': 236,\n",
       " 'last': 237,\n",
       " 'unexpected': 238,\n",
       " 'twists': 239,\n",
       " 'captivating': 240,\n",
       " 'storyline': 241,\n",
       " 'evolving': 242,\n",
       " 'at': 243,\n",
       " 'pace': 244,\n",
       " 'influencing': 245,\n",
       " 'aspect': 246,\n",
       " 'from': 247,\n",
       " 'communication': 248,\n",
       " 'medicine': 249,\n",
       " 'mountain': 250,\n",
       " 'peaks': 251,\n",
       " 'were': 252,\n",
       " 'covered': 253,\n",
       " 'snow': 254,\n",
       " 'glistening': 255,\n",
       " 'under': 256,\n",
       " 'hikers': 257,\n",
       " 'journey': 258,\n",
       " 'solved': 259,\n",
       " 'puzzle': 260,\n",
       " 'just': 261,\n",
       " 'minutes': 262,\n",
       " 'sharp': 263,\n",
       " 'thinking': 264,\n",
       " 'skills': 265,\n",
       " 'adopted': 266,\n",
       " 'cute': 267,\n",
       " 'puppy': 268,\n",
       " 'instantly': 269,\n",
       " 'falling': 270,\n",
       " 'love': 271,\n",
       " 'its': 272,\n",
       " 'playful': 273,\n",
       " 'adorable': 274,\n",
       " 'eyes': 275,\n",
       " 'ocean': 276,\n",
       " 'waves': 277,\n",
       " 'crashed': 278,\n",
       " 'against': 279,\n",
       " 'shore': 280,\n",
       " 'soothing': 281,\n",
       " 'melody': 282,\n",
       " 'resonated': 283,\n",
       " 'tranquility': 284,\n",
       " 'beach': 285,\n",
       " 'learned': 286,\n",
       " 'year': 287,\n",
       " 'practicing': 288,\n",
       " 'daily': 289,\n",
       " 'immersing': 290,\n",
       " 'herself': 291,\n",
       " 'movies': 292,\n",
       " 'conversations': 293,\n",
       " 'library': 294,\n",
       " 'genre': 295,\n",
       " 'offering': 296,\n",
       " 'knowledge': 297,\n",
       " 'entertainment': 298,\n",
       " 'avid': 299,\n",
       " 'readers': 300,\n",
       " 'built': 301,\n",
       " 'treehouse': 302,\n",
       " 'secret': 303,\n",
       " 'hideaway': 304,\n",
       " 'where': 305,\n",
       " 'read': 306,\n",
       " 'dream': 307,\n",
       " 'discovered': 308,\n",
       " 'artifact': 309,\n",
       " 'while': 310,\n",
       " 'exploring': 311,\n",
       " 'old': 312,\n",
       " 'ruins': 313,\n",
       " 'sparking': 314,\n",
       " 'curiosity': 315,\n",
       " 'among': 316,\n",
       " 'archaeologists': 317,\n",
       " 'scientist': 318,\n",
       " 'conducted': 319,\n",
       " 'experiments': 320,\n",
       " 'effects': 321,\n",
       " 'climate': 322,\n",
       " 'change': 323,\n",
       " 'marine': 324,\n",
       " 'ecosystems': 325,\n",
       " 'hiked': 326,\n",
       " 'dense': 327,\n",
       " 'forest': 328,\n",
       " 'listening': 329,\n",
       " 'sounds': 330,\n",
       " 'rustling': 331,\n",
       " 'leaves': 332,\n",
       " 'detective': 333,\n",
       " 'examined': 334,\n",
       " 'crime': 335,\n",
       " 'scene': 336,\n",
       " 'searching': 337,\n",
       " 'clues': 338,\n",
       " 'mystery': 339,\n",
       " 'hours': 340,\n",
       " 'programming': 341,\n",
       " 'application': 342,\n",
       " 'determined': 343,\n",
       " 'using': 344,\n",
       " 'algorithms': 345,\n",
       " 'wrote': 346,\n",
       " 'journal': 347,\n",
       " 'documenting': 348,\n",
       " 'thoughts': 349,\n",
       " 'experiences': 350,\n",
       " 'dreams': 351,\n",
       " 'future': 352,\n",
       " 'boy': 353,\n",
       " 'awe': 354,\n",
       " 'magician': 355,\n",
       " 'performed': 356,\n",
       " 'tricks': 357,\n",
       " 'stage': 358,\n",
       " 'set': 359,\n",
       " 'telescope': 360,\n",
       " 'observe': 361,\n",
       " 'stars': 362,\n",
       " 'planets': 363,\n",
       " 'chef': 364,\n",
       " 'delicious': 365,\n",
       " 'course': 366,\n",
       " 'meal': 367,\n",
       " 'guests': 368,\n",
       " 'exquisite': 369,\n",
       " 'presentation': 370,\n",
       " 'athlete': 371,\n",
       " 'rigorously': 372,\n",
       " 'marathon': 373,\n",
       " 'pushing': 374,\n",
       " 'limits': 375,\n",
       " 'achieve': 376,\n",
       " 'personal': 377,\n",
       " 'best': 378,\n",
       " 'planted': 379,\n",
       " 'vegetable': 380,\n",
       " 'garden': 381,\n",
       " 'growing': 382,\n",
       " 'fresh': 383,\n",
       " 'tomatoes': 384,\n",
       " 'cucumbers': 385,\n",
       " 'peppers': 386,\n",
       " 'kitchen': 387,\n",
       " 'city': 388,\n",
       " 'bustling': 389,\n",
       " 'energy': 390,\n",
       " 'rushing': 391,\n",
       " 'work': 392,\n",
       " 'street': 393,\n",
       " 'vendors': 394,\n",
       " 'selling': 395,\n",
       " 'food': 396,\n",
       " 'cars': 397,\n",
       " 'honking': 398,\n",
       " 'afternoon': 399,\n",
       " 'painting': 400,\n",
       " 'mural': 401,\n",
       " 'bringing': 402,\n",
       " 'vibrant': 403,\n",
       " 'colors': 404,\n",
       " 'otherwise': 405,\n",
       " 'dull': 406,\n",
       " 'wall': 407,\n",
       " 'pilot': 408,\n",
       " 'skillfully': 409,\n",
       " 'navigated': 410,\n",
       " 'plane': 411,\n",
       " 'turbulent': 412,\n",
       " 'weather': 413,\n",
       " 'smooth': 414,\n",
       " 'landing': 415,\n",
       " 'passengers': 416,\n",
       " 'musician': 417,\n",
       " 'composed': 418,\n",
       " 'symphony': 419,\n",
       " 'blending': 420,\n",
       " 'classical': 421,\n",
       " 'modern': 422,\n",
       " 'elements': 423,\n",
       " 'create': 424,\n",
       " 'masterpiece': 425,\n",
       " 'organized': 426,\n",
       " 'surprise': 427,\n",
       " 'birthday': 428,\n",
       " 'party': 429,\n",
       " 'inviting': 430,\n",
       " 'friends': 431,\n",
       " 'decorating': 432,\n",
       " 'venue': 433,\n",
       " 'balloons': 434,\n",
       " 'lights': 435,\n",
       " 'historian': 436,\n",
       " 'studied': 437,\n",
       " 'manuscripts': 438,\n",
       " 'uncovering': 439,\n",
       " 'secrets': 440,\n",
       " 'lost': 441,\n",
       " 'civilizations': 442,\n",
       " 'doctor': 443,\n",
       " 'worked': 444,\n",
       " 'tirelessly': 445,\n",
       " 'hospital': 446,\n",
       " 'treating': 447,\n",
       " 'patients': 448,\n",
       " 'saving': 449,\n",
       " 'lives': 450,\n",
       " 'astronaut': 451,\n",
       " 'before': 452,\n",
       " 'embarking': 453,\n",
       " 'mission': 454,\n",
       " 'international': 455,\n",
       " 'station': 456,\n",
       " 'designed': 457,\n",
       " 'gadget': 458,\n",
       " 'translate': 459,\n",
       " 'spoken': 460,\n",
       " 'real': 461,\n",
       " 'novelist': 462,\n",
       " 'writing': 463,\n",
       " 'book': 464,\n",
       " 'crafting': 465,\n",
       " 'characters': 466,\n",
       " 'plot': 467,\n",
       " 'storm': 468,\n",
       " 'raged': 469,\n",
       " 'outside': 470,\n",
       " 'thunderclaps': 471,\n",
       " 'lightning': 472,\n",
       " 'illuminating': 473,\n",
       " 'dark': 474,\n",
       " 'farmer': 475,\n",
       " 'woke': 476,\n",
       " 'early': 477,\n",
       " 'tend': 478,\n",
       " 'crops': 479,\n",
       " 'received': 480,\n",
       " 'enough': 481,\n",
       " 'water': 482,\n",
       " 'care': 483,\n",
       " 'philosopher': 484,\n",
       " 'pondered': 485,\n",
       " 'deep': 486,\n",
       " 'questions': 487,\n",
       " 'meaning': 488,\n",
       " 'existence': 489,\n",
       " 'engineer': 490,\n",
       " 'developed': 491,\n",
       " 'ai': 492,\n",
       " 'system': 493,\n",
       " 'assist': 494,\n",
       " 'doctors': 495,\n",
       " 'diagnosing': 496,\n",
       " 'diseases': 497,\n",
       " 'explorer': 498,\n",
       " 'ventured': 499,\n",
       " 'amazon': 500,\n",
       " 'rainforest': 501,\n",
       " 'discovering': 502,\n",
       " 'rare': 503,\n",
       " 'species': 504,\n",
       " 'plants': 505,\n",
       " 'animals': 506,\n",
       " 'teacher': 507,\n",
       " 'inspired': 508,\n",
       " 'students': 509,\n",
       " 'lessons': 510,\n",
       " 'made': 511,\n",
       " 'fun': 512,\n",
       " 'exciting': 513,\n",
       " 'firefighter': 514,\n",
       " 'bravely': 515,\n",
       " 'rushed': 516,\n",
       " 'burning': 517,\n",
       " 'building': 518,\n",
       " 'rescuing': 519,\n",
       " 'trapped': 520,\n",
       " 'inside': 521}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for i in range(1,len(tokenized_sentence)):\n",
    "    input_sequences.append(tokenized_sentence[:i+1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127],\n",
       " [2,\n",
       "  31,\n",
       "  120,\n",
       "  6,\n",
       "  2,\n",
       "  121,\n",
       "  122,\n",
       "  4,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  2,\n",
       "  25,\n",
       "  21,\n",
       "  2,\n",
       "  32,\n",
       "  126,\n",
       "  5,\n",
       "  22,\n",
       "  127]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seq = pad_sequences(input_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22, 127]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_seq[:,:-1]\n",
    "y = padded_seq[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22],\n",
       "       [  2,  31, 120,   6,   2, 121, 122,   4, 123, 124, 125,   2,  25,\n",
       "         21,   2,  32, 126,   5,  22]], dtype=int32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y,num_classes=521)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(521,200,input_length=19))\n",
    "model.add(LSTM(2, return_sequences=True))\n",
    "model.add(LSTM(2, return_sequences=True))\n",
    "model.add(LSTM(2, return_sequences=True))\n",
    "model.add(LSTM(2, return_sequences=True))\n",
    "model.add(LSTM(2, return_sequences=True))\n",
    "model.add(LSTM(2, return_sequences=True))\n",
    "model.add(LSTM(2, return_sequences=True))\n",
    "model.add(LSTM(2, return_sequences=True))\n",
    "model.add(LSTM(2))\n",
    "# model.add(Dense(256, activation='relu')),\n",
    "model.add(Dense(521, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " lstm_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " lstm_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " lstm_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " lstm_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " lstm_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " lstm_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " lstm_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " lstm_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " lstm_17 (\u001b[38;5;33mLSTM\u001b[0m)                   ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)                   ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " lstm_19 (\u001b[38;5;33mLSTM\u001b[0m)                   ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " lstm_20 (\u001b[38;5;33mLSTM\u001b[0m)                   ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " lstm_21 (\u001b[38;5;33mLSTM\u001b[0m)                   ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " lstm_22 (\u001b[38;5;33mLSTM\u001b[0m)                   ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " lstm_23 (\u001b[38;5;33mLSTM\u001b[0m)                   ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " lstm_24 (\u001b[38;5;33mLSTM\u001b[0m)                   ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " lstm_25 (\u001b[38;5;33mLSTM\u001b[0m)                   ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " dense_7 (\u001b[38;5;33mDense\u001b[0m)                  ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.2313 - loss: 6.2552  \n",
      "Epoch 2/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 6.2507\n",
      "Epoch 3/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.2460\n",
      "Epoch 4/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.2413\n",
      "Epoch 5/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.2363\n",
      "Epoch 6/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.2313\n",
      "Epoch 7/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.2261\n",
      "Epoch 8/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.2207\n",
      "Epoch 9/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 6.2151\n",
      "Epoch 10/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.2093\n",
      "Epoch 11/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.2033\n",
      "Epoch 12/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 6.1971\n",
      "Epoch 13/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.1907\n",
      "Epoch 14/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.1839\n",
      "Epoch 15/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 6.1769\n",
      "Epoch 16/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.1696\n",
      "Epoch 17/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 6.1620\n",
      "Epoch 18/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.1541\n",
      "Epoch 19/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.1458\n",
      "Epoch 20/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.1372\n",
      "Epoch 21/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.1282\n",
      "Epoch 22/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.1188\n",
      "Epoch 23/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.1090\n",
      "Epoch 24/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.0987\n",
      "Epoch 25/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.0881\n",
      "Epoch 26/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.0770\n",
      "Epoch 27/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.0655\n",
      "Epoch 28/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.0535\n",
      "Epoch 29/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.0412\n",
      "Epoch 30/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.0283\n",
      "Epoch 31/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.0151\n",
      "Epoch 32/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.0014\n",
      "Epoch 33/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.9874\n",
      "Epoch 34/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.9729\n",
      "Epoch 35/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.9582\n",
      "Epoch 36/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 5.9431\n",
      "Epoch 37/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.9277\n",
      "Epoch 38/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.9120\n",
      "Epoch 39/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.8961\n",
      "Epoch 40/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.8800\n",
      "Epoch 41/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 5.8637\n",
      "Epoch 42/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.8473\n",
      "Epoch 43/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.8308\n",
      "Epoch 44/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.8142\n",
      "Epoch 45/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.7976\n",
      "Epoch 46/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.7809\n",
      "Epoch 47/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.7642\n",
      "Epoch 48/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.7476\n",
      "Epoch 49/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.7309\n",
      "Epoch 50/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.7143\n",
      "Epoch 51/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.6977\n",
      "Epoch 52/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.6812\n",
      "Epoch 53/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.6647\n",
      "Epoch 54/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.6483\n",
      "Epoch 55/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.6320\n",
      "Epoch 56/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.6157\n",
      "Epoch 57/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.5994\n",
      "Epoch 58/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.5832\n",
      "Epoch 59/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.5671\n",
      "Epoch 60/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 5.5510\n",
      "Epoch 61/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.5350\n",
      "Epoch 62/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.5190\n",
      "Epoch 63/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 5.5030\n",
      "Epoch 64/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 5.4871\n",
      "Epoch 65/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.4712\n",
      "Epoch 66/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 5.4553\n",
      "Epoch 67/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.4395\n",
      "Epoch 68/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.4236\n",
      "Epoch 69/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.4078\n",
      "Epoch 70/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.3921\n",
      "Epoch 71/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.3763\n",
      "Epoch 72/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.3605\n",
      "Epoch 73/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.3448\n",
      "Epoch 74/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.3290\n",
      "Epoch 75/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.3133\n",
      "Epoch 76/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.2976\n",
      "Epoch 77/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.2819\n",
      "Epoch 78/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.2661\n",
      "Epoch 79/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.2504\n",
      "Epoch 80/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.2347\n",
      "Epoch 81/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.2190\n",
      "Epoch 82/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.2033\n",
      "Epoch 83/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.1876\n",
      "Epoch 84/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.1718\n",
      "Epoch 85/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.1561\n",
      "Epoch 86/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.1404\n",
      "Epoch 87/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.1247\n",
      "Epoch 88/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.1090\n",
      "Epoch 89/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.0933\n",
      "Epoch 90/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.0775\n",
      "Epoch 91/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.0618\n",
      "Epoch 92/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.0461\n",
      "Epoch 93/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.0304\n",
      "Epoch 94/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.0147\n",
      "Epoch 95/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.9990\n",
      "Epoch 96/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.9832\n",
      "Epoch 97/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.9675\n",
      "Epoch 98/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.9518\n",
      "Epoch 99/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.9361\n",
      "Epoch 100/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.9204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3130ac260>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step\n",
      "Artificial intelligence nests\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Artificial intelligence nests nests\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Artificial intelligence nests nests nests\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Artificial intelligence nests nests nests nests\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Artificial intelligence nests nests nests nests nests\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Artificial intelligence nests nests nests nests nests nests\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Artificial intelligence nests nests nests nests nests nests nests\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Artificial intelligence nests nests nests nests nests nests nests nests\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Artificial intelligence nests nests nests nests nests nests nests nests nests\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Artificial intelligence nests nests nests nests nests nests nests nests nests nests\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text = \"Artificial intelligence\"\n",
    "\n",
    "for i in range(10):\n",
    "  # tokenize\n",
    "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "  # padding\n",
    "  padded_token_text = pad_sequences([token_text], maxlen=29, padding='pre')\n",
    "  # predict\n",
    "  pos = np.argmax(model.predict(padded_token_text))\n",
    "\n",
    "  for word,index in tokenizer.word_index.items():\n",
    "    if index == pos:\n",
    "      text = text + \" \" + word\n",
    "      print(text)\n",
    "      time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
